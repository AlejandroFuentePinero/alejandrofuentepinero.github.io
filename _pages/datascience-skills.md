---
title: "Skills"
permalink: /datascience/skills/
layout: single
---

## Summary
Data scientist with a **research-grade modelling foundation** (spatiotemporal + hierarchical Bayesian population modelling) and **end-to-end ML delivery** (Python pipelines, evaluation, interpretability, recommender outputs). Strong scientific communication, project leadership, and publication record.

---

## 1) Research & Modelling (Academic Umbrella)
- Population modelling and inference under uncertainty (ecological/field data)  
- **Hierarchical Bayesian** modelling (partial pooling, uncertainty-first reporting)  
- **Spatiotemporal** modelling mindset (structured dependence, forecasting logic)  
- Observation vs process modelling (e.g., detectionâ€“abundance separation template)  
- Reproducible research workflows (transparent methods, defensible assumptions)

---

## 2) Data Science Workflow
- EDA, data cleaning, missingness strategies, outliers, leakage checks, sanity checks  
- Feature engineering: encoding, scaling, transformations, selection  
- Validation design: train/val/test, cross-validation, baseline discipline, overfitting control  
- Evaluation: classification/regression metrics, calibration awareness, error analysis  
- Reproducibility: deterministic runs, configs, artefact generation, documentation

---

## 3) Machine Learning (Classical)
- Supervised: linear/logistic regression, trees, random forests, gradient boosting, SVM, k-NN  
- Unsupervised: K-Means clustering, anomaly detection fundamentals  
- scikit-learn Pipelines; hyperparameter tuning; model comparison  
- Gradient boosting (incl. **XGBoost**) and practical performance tuning patterns

---

## 4) Deep Learning (Foundations)
- Feedforward neural networks (classification/regression)  
- Training concepts: activation functions, loss/optimisers, regularisation, train/val monitoring  
- **TensorFlow / Keras** fundamentals (model definition, training loops, evaluation)

---

## 5) NLP & Recommenders (Applied Foundations)
- Text cleaning/normalisation; tokenisation; feature inspection  
- Vectorisation: CountVectorizer, TF-IDF; Naive Bayes baselines  
- Recommender foundations: similarity metrics, collaborative filtering, constraint-aware framing

---

## 6) Interpretability, Diagnostics & Reporting
- Feature importance; partial dependence style diagnostics  
- SHAP-style global/local explanation workflows (where appropriate)  
- Model debugging: residual/error slicing, failure modes, robustness checks  
- Decision-ready reporting (clear tradeoffs, assumptions, limitations)

---

## 7) Programming & Libraries
- **Python (primary):** pandas, NumPy, scikit-learn, matplotlib, seaborn, plotly; regex; logging; OOP  
- **R:** tidyverse, ggplot2; sf/terra; Shiny familiarity  
- **SQL:** PostgreSQL (joins, CTEs, window functions, views, NULL-safe patterns)

---

## 8) Data Engineering, I/O & Integration
- Data ingestion/processing: CSV/Excel/text; file I/O; schema discipline  
- Web data basics: requests + BeautifulSoup; PDF parsing basics  
- Integration patterns: API + SQL workflows; joining complex relational datasets

---

## 9) Software Engineering & Reproducibility
- Git/GitHub: branching/merging, PR workflow, conflict resolution, diff-driven review  
- Environments: venv/conda (Python), renv (R)  
- Code quality: assertions/validation utilities, docstrings, type hints where useful, pytest-style testing patterns  
- Modular architecture: reusable modules, script-to-pipeline conversion, clean interfaces

---

## 10) Databases & Storage
- PostgreSQL setup and querying; analytics-oriented schema reasoning  
- Microsoft Access (legacy support)

---

## 11) Visualisation & Dashboards
- EDA + diagnostic plots in Python/R  
- Interactive outputs: Streamlit (Python), Shiny familiarity (R), Plotly

---

## 12) Geospatial & Remote Sensing
- Raster/vector workflows; spatial joins; geoprocessing pipelines  
- Spatial feature engineering; canopy/landscape metrics  
- Parallelised spatial workflows where appropriate

---

## 13) LLMs, Prompt Engineering & Agents (Foundations)
- Prompt engineering for summarisation, classification, transformation, generation  
- Reliability patterns: structured prompts, iterative refinement, evaluation loops  
- Agentic patterns: planning/acting/reflection loops, tool calling, retrieval, multi-agent coordination  
- Graph-style orchestration concepts (LangGraph): state, control flow, tracing/debugging, retries, HITL stages

---

## 14) Communication, Leadership & Delivery
- Peer-reviewed writing; methods-first documentation; reproducible reporting  
- Conference presentations; stakeholder briefings; scientific storytelling  
- Teaching and mentoring (students/collaborators; code + modelling support)  
- Project management: scoping, prioritisation, milestones, delivery under constraints  
- Collaboration: cross-disciplinary teamwork, feedback loops, iterative improvement

---

## Education & Training
A detailed, certificate-linked list of formal education and courses is maintained here: **/datascience/education/**
